{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IsD4mAzMFXs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.stats import zscore\n",
        "import copy\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "import torchvision\n",
        "import torchvision.transforms as tt\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import MNIST, ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split, DataLoader, Subset, SubsetRandomSampler\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "OV5K4fe2Oj-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYx8synfN5t0"
      },
      "source": [
        "transform = tt.Compose([tt.ToTensor(),\n",
        "                    tt.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_ds = MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_ds = MNIST(root='.', train=False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_UGSS5VYbHh"
      },
      "source": [
        "batch_size=100\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers = 4, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size, num_workers = 4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "caTHV6-MY1ZC",
        "outputId": "e4e54f94-c23e-4872-85ac-bdaa73267819"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic7FRbWGZR9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae553b32-215a-4d91-9cf2-5ae288d03f5d"
      },
      "source": [
        "class MnistNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(1, 10, 5),\n",
        "                                  nn.MaxPool2d(2),\n",
        "                                  nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(10, 20, kernel_size=5),\n",
        "                                  nn.Dropout2d(),\n",
        "                                  nn.MaxPool2d(2),\n",
        "                                  nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(nn.Flatten(),\n",
        "                                nn.Linear(320, 50),\n",
        "                                nn.Dropout(),\n",
        "                                nn.ReLU())\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(MnistNet())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MnistNet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Dropout2d(p=0.5, inplace=False)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=320, out_features=50, bias=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heolWQ0tc40Q"
      },
      "source": [
        "def test(model, test_dl, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        batch_loss, batch_acc = [], []\n",
        "        for images, labels in test_dl:\n",
        "            if torch.cuda.is_available():\n",
        "              images = images.cuda()\n",
        "              # labels = torch.tensor(labels)\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            batch_loss.append(loss.cpu())\n",
        "            pred = torch.argmax(logits, dim=1)\n",
        "            batch_acc.append(accuracy_score(labels.cpu(), pred.cpu()))\n",
        "        model.cpu()\n",
        "        return sum(batch_loss)/len(batch_loss), sum(batch_acc)/len(batch_acc)\n",
        "\n",
        "def fit(epochs, model, optimizer, criterion, train_dl, test_dl):\n",
        "    train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
        "    attack=None\n",
        "    train_attack=[]\n",
        "    for epoch in range(1,epochs+1):\n",
        "        val=random.random()\n",
        "        if val>0.20:\n",
        "          attack=True\n",
        "        else:\n",
        "          attack=False\n",
        "\n",
        "        trainl, traina, _ = train(model, train_dl, optimizer,attack)\n",
        "        testl , testa = test(model, test_dl, criterion)\n",
        "        train_loss.append(trainl.detach().numpy())\n",
        "        train_acc.append(traina)\n",
        "\n",
        "        train_attack.append(attack)\n",
        "\n",
        "        test_loss.append(testl.detach().numpy())\n",
        "        test_acc.append(testa)\n",
        "        print(f'Epoch {epoch} - train_loss : {trainl :.4f}, train_acc : {traina:.4f}, test_loss : {testl:.4f}, test_acc : {testa:0.4f}')\n",
        "\n",
        "    history = {'train_loss' : train_loss,\n",
        "               'train_acc' : train_acc,\n",
        "               'test_loss' : test_loss,\n",
        "               'test_acc' : test_acc,\n",
        "               'train_attacked_history' : train_attack}\n",
        "    return history\n",
        "\n",
        "epochs = 3\n",
        "model = MnistNet()\n",
        "optimizer = Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# baseline_history = fit(epochs, model, optimizer, criterion, train_dl, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with attack"
      ],
      "metadata": {
        "id": "zZn20rnrZJST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std_dev = 1 ###################### Attack 2 Parameter\n",
        "\n",
        "\"\"\"\n",
        "Get historical gradients\n",
        "\"\"\"\n",
        "def train(model, train_dl, optimizer, ID, attack_type, attack=False, hist_grads=None):\n",
        "    model.to(device)\n",
        "\n",
        "    # get global weight\n",
        "    global_w = deepcopy(model.state_dict())\n",
        "    global_w = torch.cat([v.flatten() for v in global_w.values()])\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    batch_loss, batch_acc = [], []\n",
        "    for images, labels in train_dl:\n",
        "        if attack and attack_type == 'A1': ###################### Attack 1\n",
        "            labels = label_poisoning(labels)\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images = images.float()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clipping the gradients\n",
        "        max_grad_norm = 1.0\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        # Adding noise\n",
        "        for param in model.parameters():\n",
        "            noise = torch.normal(0, std_dev, param.grad.shape, device=device)\n",
        "            param.grad += noise / len(train_dl)\n",
        "\n",
        "        # get local weight and gradient\n",
        "        local_w = deepcopy(model.state_dict())\n",
        "\n",
        "        optimizer.step()\n",
        "        batch_loss.append(loss.cpu())\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        batch_acc.append(accuracy_score(labels.cpu(), pred.cpu()))\n",
        "\n",
        "    hist_grads.append(local_w)\n",
        "\n",
        "    # mean of historical gradients\n",
        "    mean_weights = {}\n",
        "    for key in hist_grads[0]:\n",
        "        param_stack = torch.stack([w[key] for w in hist_grads])\n",
        "        mean_weights[key] = torch.mean(param_stack, dim=0)\n",
        "    local_w_mean = torch.cat([v.flatten() for v in mean_weights.values()])\n",
        "\n",
        "    # current gradient\n",
        "    local_w = torch.cat([v.flatten() for v in local_w.values()])\n",
        "\n",
        "    model.cpu()\n",
        "\n",
        "    # print(\"local_w_mean?\", local_w_mean.values == local_w.values)\n",
        "\n",
        "    return sum(batch_loss)/len(batch_loss), sum(batch_acc)/len(batch_acc), hist_grads, local_w_mean, local_w\n",
        "\n",
        "# flip all with 7 into 1\n",
        "def label_poisoning(label):\n",
        "    source_label=7\n",
        "    target_label=1\n",
        "    label[label == source_label] = target_label\n",
        "    return label"
      ],
      "metadata": {
        "id": "O4aVPAATZOEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njdb15hClCfY"
      },
      "source": [
        "# Train Clients\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Method 0\n",
        "'''\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def find_attacker_id(clf):\n",
        "    count_1 = sum(clf.labels_ == 1)\n",
        "    count_0 = sum(clf.labels_ == 0)\n",
        "    mal_label = 0 if count_1 > count_0 else 1\n",
        "    atk_id = np.where(clf.labels_ == mal_label)[0]\n",
        "    atk_id = set(atk_id.reshape((-1)))\n",
        "    return atk_id\n",
        "\n",
        "def find_targeted_attack(dict_hist_grad):\n",
        "    value_hist_grad = np.array([v.cpu().numpy() for v in dict_hist_grad.values()])\n",
        "    id_hist_grad = np.array(list(dict_hist_grad.keys()))\n",
        "\n",
        "    cluster = KMeans(n_clusters=2, random_state=0).fit(value_hist_grad)\n",
        "\n",
        "    attacker = find_attacker_id(cluster)\n",
        "    attacker_id = id_hist_grad[list(attacker)]\n",
        "\n",
        "    logging.info(f\"This round TARGETED ATTACK: {attacker_id}\")\n",
        "\n",
        "    return attacker_id"
      ],
      "metadata": {
        "id": "mEW4hE4L3DSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJXESEctevc"
      },
      "source": [
        "def train_clients(hist_grad_all, client_models, client_optimizers, server_model, criterion, client_dls, num, attackers):\n",
        "    client_loss, client_acc = [], []\n",
        "    attacked_clients = []\n",
        "    client_curr_grads_dicts = [{} for _ in client_models]\n",
        "    client_hist_grads_dicts_mean = [{} for _ in client_models]\n",
        "\n",
        "    for i, (model, optimizer, train_dl) in enumerate(zip(client_models, client_optimizers, client_dls)):\n",
        "        model.load_state_dict(server_model.state_dict())\n",
        "\n",
        "        hist_grads = hist_grad_all[i]\n",
        "\n",
        "        is_attacked = False\n",
        "        attack_type = '0'\n",
        "        if (i in attackers):\n",
        "            is_attacked = True\n",
        "            attack_type = 'A1'\n",
        "\n",
        "        attacked_clients.append(is_attacked)\n",
        "\n",
        "        closs, cacc, hist_grads, local_w_mean, curr_grads = train(model, train_dl, optimizer, i, attack_type, is_attacked, hist_grads=hist_grads)\n",
        "\n",
        "        client_loss.append(closs)\n",
        "        client_acc.append(cacc)\n",
        "        hist_grad_all[i] = hist_grads\n",
        "        client_hist_grads_dicts_mean[i] = local_w_mean\n",
        "        client_curr_grads_dicts[i] = curr_grads\n",
        "\n",
        "    client_hist_grads_formatted = {client_id: local_w_mean for client_id, local_w_mean in enumerate(client_hist_grads_dicts_mean)}\n",
        "    client_curr_grads_formatted = {client_id: curr_grads for client_id, curr_grads in enumerate(client_curr_grads_dicts)}\n",
        "\n",
        "    return sum(client_loss)/len(client_loss), sum(client_acc)/len(client_acc), \\\n",
        "            client_hist_grads_formatted, client_curr_grads_formatted, attacked_clients\n",
        "\n",
        "def fedavg(client_models, server_model, historical_grads, current_grads):\n",
        "    server_new_dict = {}\n",
        "\n",
        "    n = len(client_models)\n",
        "    server_new_dict = {}\n",
        "    for model in client_models:\n",
        "        client_dict =  model.state_dict()\n",
        "        for name in client_dict:\n",
        "            server_new_dict[name] = server_new_dict.get(name, 0) + client_dict[name]\n",
        "    server_new_dict = {k : v/n for k, v in server_new_dict.items()}\n",
        "    server_model.load_state_dict(server_new_dict)\n",
        "\n",
        "    # Perform Cluster on historical_grads & current_grads for comparison:\n",
        "    combined_results = 'No Cluster Performed'\n",
        "    cluster_results_1 = find_targeted_attack(historical_grads)\n",
        "    print(\"cluster results of historical\", cluster_results_1)\n",
        "\n",
        "    cluster_results_2 = find_targeted_attack(current_grads)\n",
        "    print(\"cluster results of current\", cluster_results_2)\n",
        "\n",
        "    return cluster_results_1, cluster_results_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Non-IID Case\n",
        "\"\"\"\n",
        "def create_skewed_label_distribution(skewness_factor, n):\n",
        "    labels = list(range(10))  # Labels from 0 to 9\n",
        "    num_labels = len(labels)\n",
        "    client_label_distribution = {}\n",
        "\n",
        "    for client_id in range(n):\n",
        "        # Choose two primary labels for each client\n",
        "        primary_labels = np.random.choice(labels, 2, replace=False)\n",
        "        secondary_labels = [label for label in labels if label not in primary_labels]\n",
        "\n",
        "        # Assign skewness factor to primary labels\n",
        "        label_distribution = {label: (skewness_factor / 2) if label in primary_labels else ((1 - skewness_factor) / (num_labels - 2)) for label in labels}\n",
        "        client_label_distribution[client_id] = label_distribution\n",
        "\n",
        "    return client_label_distribution\n",
        "\n",
        "def create_skewed_data_loaders(dataset, n, label_distribution_map):\n",
        "    # Gather indices for each label\n",
        "    label_indices = {label: [] for label in range(10)}\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        label_indices[label].append(idx)\n",
        "\n",
        "    # Create data subsets for each client based on label distribution\n",
        "    client_datasets = []\n",
        "    for client_id in range(n):\n",
        "        client_indices = []\n",
        "        for label, proportion in label_distribution_map[client_id].items():\n",
        "            num_samples = int(proportion * len(dataset) // n)\n",
        "            client_indices += np.random.choice(label_indices[label], num_samples, replace=False).tolist()\n",
        "\n",
        "        client_datasets.append(Subset(dataset, client_indices))\n",
        "\n",
        "    # Create data loaders\n",
        "    client_dls = [DataLoader(ds, batch_size, shuffle=True, num_workers=4, pin_memory=True) for ds in client_datasets]\n",
        "\n",
        "    client_models = [MnistNet() for _ in range(n)]\n",
        "    client_optimizers = [Adam(model.parameters(), 0.001) for model in client_models]\n",
        "\n",
        "    return client_dls, client_models, client_optimizers\n",
        "\n",
        "def non_iid_clients(train_ds, n):\n",
        "    label_distribution_map = create_skewed_label_distribution(skewness_factor, n)\n",
        "    client_dls, client_models, client_optimizers = create_skewed_data_loaders(train_ds, n, label_distribution_map)\n",
        "\n",
        "    return client_dls, client_models, client_optimizers"
      ],
      "metadata": {
        "id": "4oQ8DMwtSJDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_cluster_results = []\n",
        "\n",
        "def get_attackers_indices(total_clients, attack_rate):\n",
        "    num_attackers = int(total_clients * attack_rate)\n",
        "    return random.sample(range(total_clients), num_attackers)\n",
        "\n",
        "def fit_fedavg(epochs, client_models, client_optimizers, server_model, criterion, client_dls, test_dl, num, attackers):\n",
        "    train_loss, train_acc, test_loss, test_acc, anomalies = [], [], [], [], []\n",
        "    attack=None\n",
        "    train_attack=[]\n",
        "\n",
        "    hist_grad_all = [[] for _ in client_models]\n",
        "\n",
        "    for epoch in range(1,epochs+1):\n",
        "        print(f\"----epoch {epoch}----\")\n",
        "        trainl, traina, historical_grads, current_grad, attacked_clients = train_clients(hist_grad_all, client_models, client_optimizers, server_model, criterion, client_dls, num, attackers) # ATTACK\n",
        "        cluster_results_1, cluster_results_2 = fedavg(client_models, server_model, historical_grads, current_grad)\n",
        "\n",
        "        testl , testa = test(server_model, test_dl, criterion)\n",
        "\n",
        "        formatted_trainl = f\"{trainl:.4f}\"\n",
        "        formatted_traina = f\"{traina:.4f}\"\n",
        "        formatted_testl = f\"{testl:.4f}\"\n",
        "        formatted_testa = f\"{testa:.4f}\"\n",
        "\n",
        "        all_cluster_results.append({\n",
        "            'num': num,\n",
        "            'rate': rate,\n",
        "            'round': epoch,\n",
        "            'ground truth': attackers,\n",
        "            'historical_cluster': cluster_results_1,\n",
        "            'current_cluster': cluster_results_2,\n",
        "            'train_loss': formatted_trainl,\n",
        "            'train_acc': formatted_traina,\n",
        "            'test_loss': formatted_testl,\n",
        "            'test_acc': formatted_testa\n",
        "        })\n",
        "        print(\"hey\", formatted_trainl)\n",
        "        print(f'Epoch {epoch} - train_loss : {trainl :.4f}, train_acc : {traina:.4f}, test_loss : {testl:.4f}, test_acc : {testa:0.4f}')\n",
        "\n",
        "    return all_cluster_results"
      ],
      "metadata": {
        "id": "jaqBuAGemh62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "# for skewness_factor in [0.3, 0.5, 0.7]: # degree of non-IID\n",
        "#     print(f\"---------------------skewness_factor {skewness_factor}------------------------\")\n",
        "\n",
        "skewness_factor = 0.7\n",
        "# for n in [10, 20, 50]: # client num\n",
        "#     print(f\"---------------------client num {n}------------------------\")\n",
        "\n",
        "n = 10\n",
        "client_dls_list, client_models, client_optimizers = non_iid_clients(train_ds, n)\n",
        "\n",
        "\n",
        "for rate in [0.125, 0.20, 0.275, 0.35, 0.425, 0.475]: # malicious rate\n",
        "    print(f\"---------------------rate {rate}------------------------\")\n",
        "\n",
        "    server_model = MnistNet()\n",
        "    # generate attackers\n",
        "    attackers = get_attackers_indices(n, rate)\n",
        "    print(\"attackers are \", attackers)\n",
        "\n",
        "    # train and detection\n",
        "    all_cluster_results = fit_fedavg(epochs, client_models, client_optimizers, server_model, criterion, client_dls_list, test_dl, n, attackers)\n",
        "\n",
        "    with open('nonIID_w_dpsgd.csv', mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['num', 'rate', 'round', 'ground truth', 'historical_cluster', 'current_cluster','train_loss','train_acc','test_loss','test_acc'])\n",
        "        writer.writeheader()\n",
        "        for data in all_cluster_results:\n",
        "            writer.writerow(data)"
      ],
      "metadata": {
        "id": "5mpPkBZdf4Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93cb462-dbf2-4cff-b047-c02a369afc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------client num 10------------------------\n",
            "---------------------rate 0.125------------------------\n",
            "attackers are  [8]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.6631\n",
            "Epoch 1 - train_loss : 1.6631, train_acc : 0.5123, test_loss : 2.0005, test_acc : 0.4172\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.3081\n",
            "Epoch 2 - train_loss : 1.3081, train_acc : 0.6187, test_loss : 1.2766, test_acc : 0.6751\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 2 5 6]\n",
            "hey 0.9441\n",
            "Epoch 3 - train_loss : 0.9441, train_acc : 0.7220, test_loss : 0.8107, test_acc : 0.7888\n",
            "----epoch 4----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.7559\n",
            "Epoch 4 - train_loss : 0.7559, train_acc : 0.7709, test_loss : 0.6177, test_acc : 0.8357\n",
            "----epoch 5----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.6506\n",
            "Epoch 5 - train_loss : 0.6506, train_acc : 0.8029, test_loss : 0.5109, test_acc : 0.8653\n",
            "----epoch 6----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.5942\n",
            "Epoch 6 - train_loss : 0.5942, train_acc : 0.8216, test_loss : 0.4587, test_acc : 0.8750\n",
            "----epoch 7----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.5373\n",
            "Epoch 7 - train_loss : 0.5373, train_acc : 0.8380, test_loss : 0.4050, test_acc : 0.8885\n",
            "----epoch 8----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.5076\n",
            "Epoch 8 - train_loss : 0.5076, train_acc : 0.8490, test_loss : 0.3673, test_acc : 0.8981\n",
            "----epoch 9----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.4745\n",
            "Epoch 9 - train_loss : 0.4745, train_acc : 0.8591, test_loss : 0.3412, test_acc : 0.9045\n",
            "----epoch 10----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.4442\n",
            "Epoch 10 - train_loss : 0.4442, train_acc : 0.8684, test_loss : 0.3173, test_acc : 0.9081\n",
            "----epoch 11----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.4339\n",
            "Epoch 11 - train_loss : 0.4339, train_acc : 0.8710, test_loss : 0.3024, test_acc : 0.9140\n",
            "----epoch 12----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8]\n",
            "hey 0.4134\n",
            "Epoch 12 - train_loss : 0.4134, train_acc : 0.8772, test_loss : 0.2881, test_acc : 0.9169\n",
            "----epoch 13----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3976\n",
            "Epoch 13 - train_loss : 0.3976, train_acc : 0.8819, test_loss : 0.2762, test_acc : 0.9190\n",
            "----epoch 14----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3877\n",
            "Epoch 14 - train_loss : 0.3877, train_acc : 0.8853, test_loss : 0.2591, test_acc : 0.9253\n",
            "----epoch 15----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3713\n",
            "Epoch 15 - train_loss : 0.3713, train_acc : 0.8895, test_loss : 0.2453, test_acc : 0.9272\n",
            "----epoch 16----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3595\n",
            "Epoch 16 - train_loss : 0.3595, train_acc : 0.8933, test_loss : 0.2403, test_acc : 0.9295\n",
            "----epoch 17----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3526\n",
            "Epoch 17 - train_loss : 0.3526, train_acc : 0.8956, test_loss : 0.2289, test_acc : 0.9326\n",
            "----epoch 18----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3412\n",
            "Epoch 18 - train_loss : 0.3412, train_acc : 0.9000, test_loss : 0.2219, test_acc : 0.9342\n",
            "----epoch 19----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3362\n",
            "Epoch 19 - train_loss : 0.3362, train_acc : 0.9026, test_loss : 0.2126, test_acc : 0.9369\n",
            "----epoch 20----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3273\n",
            "Epoch 20 - train_loss : 0.3273, train_acc : 0.9038, test_loss : 0.2086, test_acc : 0.9381\n",
            "----epoch 21----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3222\n",
            "Epoch 21 - train_loss : 0.3222, train_acc : 0.9042, test_loss : 0.2004, test_acc : 0.9400\n",
            "----epoch 22----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3093\n",
            "Epoch 22 - train_loss : 0.3093, train_acc : 0.9087, test_loss : 0.1922, test_acc : 0.9420\n",
            "----epoch 23----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.3080\n",
            "Epoch 23 - train_loss : 0.3080, train_acc : 0.9095, test_loss : 0.1888, test_acc : 0.9430\n",
            "----epoch 24----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2985\n",
            "Epoch 24 - train_loss : 0.2985, train_acc : 0.9125, test_loss : 0.1831, test_acc : 0.9440\n",
            "----epoch 25----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2878\n",
            "Epoch 25 - train_loss : 0.2878, train_acc : 0.9155, test_loss : 0.1762, test_acc : 0.9456\n",
            "----epoch 26----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2854\n",
            "Epoch 26 - train_loss : 0.2854, train_acc : 0.9169, test_loss : 0.1722, test_acc : 0.9466\n",
            "----epoch 27----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2838\n",
            "Epoch 27 - train_loss : 0.2838, train_acc : 0.9165, test_loss : 0.1686, test_acc : 0.9474\n",
            "----epoch 28----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2718\n",
            "Epoch 28 - train_loss : 0.2718, train_acc : 0.9202, test_loss : 0.1633, test_acc : 0.9490\n",
            "----epoch 29----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2704\n",
            "Epoch 29 - train_loss : 0.2704, train_acc : 0.9222, test_loss : 0.1600, test_acc : 0.9510\n",
            "----epoch 30----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2669\n",
            "Epoch 30 - train_loss : 0.2669, train_acc : 0.9221, test_loss : 0.1557, test_acc : 0.9513\n",
            "----epoch 31----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2634\n",
            "Epoch 31 - train_loss : 0.2634, train_acc : 0.9229, test_loss : 0.1507, test_acc : 0.9532\n",
            "----epoch 32----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2543\n",
            "Epoch 32 - train_loss : 0.2543, train_acc : 0.9258, test_loss : 0.1473, test_acc : 0.9539\n",
            "----epoch 33----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2624\n",
            "Epoch 33 - train_loss : 0.2624, train_acc : 0.9232, test_loss : 0.1447, test_acc : 0.9550\n",
            "----epoch 34----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2504\n",
            "Epoch 34 - train_loss : 0.2504, train_acc : 0.9262, test_loss : 0.1399, test_acc : 0.9566\n",
            "----epoch 35----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2470\n",
            "Epoch 35 - train_loss : 0.2470, train_acc : 0.9275, test_loss : 0.1415, test_acc : 0.9560\n",
            "----epoch 36----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2461\n",
            "Epoch 36 - train_loss : 0.2461, train_acc : 0.9285, test_loss : 0.1362, test_acc : 0.9584\n",
            "----epoch 37----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2414\n",
            "Epoch 37 - train_loss : 0.2414, train_acc : 0.9300, test_loss : 0.1334, test_acc : 0.9587\n",
            "----epoch 38----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2388\n",
            "Epoch 38 - train_loss : 0.2388, train_acc : 0.9302, test_loss : 0.1312, test_acc : 0.9594\n",
            "----epoch 39----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2336\n",
            "Epoch 39 - train_loss : 0.2336, train_acc : 0.9325, test_loss : 0.1294, test_acc : 0.9589\n",
            "----epoch 40----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2322\n",
            "Epoch 40 - train_loss : 0.2322, train_acc : 0.9321, test_loss : 0.1269, test_acc : 0.9602\n",
            "----epoch 41----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2325\n",
            "Epoch 41 - train_loss : 0.2325, train_acc : 0.9345, test_loss : 0.1229, test_acc : 0.9613\n",
            "----epoch 42----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2298\n",
            "Epoch 42 - train_loss : 0.2298, train_acc : 0.9338, test_loss : 0.1221, test_acc : 0.9622\n",
            "----epoch 43----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2281\n",
            "Epoch 43 - train_loss : 0.2281, train_acc : 0.9349, test_loss : 0.1174, test_acc : 0.9637\n",
            "----epoch 44----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2239\n",
            "Epoch 44 - train_loss : 0.2239, train_acc : 0.9354, test_loss : 0.1184, test_acc : 0.9638\n",
            "----epoch 45----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2259\n",
            "Epoch 45 - train_loss : 0.2259, train_acc : 0.9359, test_loss : 0.1163, test_acc : 0.9639\n",
            "----epoch 46----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2197\n",
            "Epoch 46 - train_loss : 0.2197, train_acc : 0.9365, test_loss : 0.1155, test_acc : 0.9646\n",
            "----epoch 47----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2158\n",
            "Epoch 47 - train_loss : 0.2158, train_acc : 0.9375, test_loss : 0.1134, test_acc : 0.9654\n",
            "----epoch 48----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2119\n",
            "Epoch 48 - train_loss : 0.2119, train_acc : 0.9383, test_loss : 0.1106, test_acc : 0.9660\n",
            "----epoch 49----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2145\n",
            "Epoch 49 - train_loss : 0.2145, train_acc : 0.9390, test_loss : 0.1103, test_acc : 0.9663\n",
            "----epoch 50----\n",
            "cluster results of historical [8]\n",
            "cluster results of current [8]\n",
            "hey 0.2106\n",
            "Epoch 50 - train_loss : 0.2106, train_acc : 0.9391, test_loss : 0.1082, test_acc : 0.9668\n",
            "---------------------rate 0.2------------------------\n",
            "attackers are  [7, 4]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.7317\n",
            "Epoch 1 - train_loss : 1.7317, train_acc : 0.4808, test_loss : 2.0607, test_acc : 0.3350\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.2998\n",
            "Epoch 2 - train_loss : 1.2998, train_acc : 0.6253, test_loss : 1.3982, test_acc : 0.5653\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 3 5 6]\n",
            "hey 0.9735\n",
            "Epoch 3 - train_loss : 0.9735, train_acc : 0.7074, test_loss : 0.9149, test_acc : 0.7283\n",
            "----epoch 4----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [4]\n",
            "hey 0.7886\n",
            "Epoch 4 - train_loss : 0.7886, train_acc : 0.7593, test_loss : 0.6879, test_acc : 0.8133\n",
            "----epoch 5----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [4 7]\n",
            "hey 0.6781\n",
            "Epoch 5 - train_loss : 0.6781, train_acc : 0.7926, test_loss : 0.5572, test_acc : 0.8483\n",
            "----epoch 6----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [4 7]\n",
            "hey 0.6049\n",
            "Epoch 6 - train_loss : 0.6049, train_acc : 0.8155, test_loss : 0.4733, test_acc : 0.8696\n",
            "----epoch 7----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [4]\n",
            "hey 0.5655\n",
            "Epoch 7 - train_loss : 0.5655, train_acc : 0.8294, test_loss : 0.4327, test_acc : 0.8809\n",
            "----epoch 8----\n",
            "cluster results of historical [1 2 4 7 8]\n",
            "cluster results of current [4]\n",
            "hey 0.5273\n",
            "Epoch 8 - train_loss : 0.5273, train_acc : 0.8404, test_loss : 0.3991, test_acc : 0.8874\n",
            "----epoch 9----\n",
            "cluster results of historical [1 2 4 7 8]\n",
            "cluster results of current [4 7]\n",
            "hey 0.5005\n",
            "Epoch 9 - train_loss : 0.5005, train_acc : 0.8509, test_loss : 0.3660, test_acc : 0.8945\n",
            "----epoch 10----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.4708\n",
            "Epoch 10 - train_loss : 0.4708, train_acc : 0.8587, test_loss : 0.3471, test_acc : 0.8984\n",
            "----epoch 11----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.4497\n",
            "Epoch 11 - train_loss : 0.4497, train_acc : 0.8652, test_loss : 0.3212, test_acc : 0.9072\n",
            "----epoch 12----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.4359\n",
            "Epoch 12 - train_loss : 0.4359, train_acc : 0.8705, test_loss : 0.3110, test_acc : 0.9096\n",
            "----epoch 13----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.4212\n",
            "Epoch 13 - train_loss : 0.4212, train_acc : 0.8747, test_loss : 0.2979, test_acc : 0.9127\n",
            "----epoch 14----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.4094\n",
            "Epoch 14 - train_loss : 0.4094, train_acc : 0.8798, test_loss : 0.2825, test_acc : 0.9167\n",
            "----epoch 15----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3939\n",
            "Epoch 15 - train_loss : 0.3939, train_acc : 0.8820, test_loss : 0.2727, test_acc : 0.9178\n",
            "----epoch 16----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3886\n",
            "Epoch 16 - train_loss : 0.3886, train_acc : 0.8849, test_loss : 0.2683, test_acc : 0.9205\n",
            "----epoch 17----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3766\n",
            "Epoch 17 - train_loss : 0.3766, train_acc : 0.8894, test_loss : 0.2534, test_acc : 0.9249\n",
            "----epoch 18----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3663\n",
            "Epoch 18 - train_loss : 0.3663, train_acc : 0.8914, test_loss : 0.2525, test_acc : 0.9254\n",
            "----epoch 19----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3545\n",
            "Epoch 19 - train_loss : 0.3545, train_acc : 0.8947, test_loss : 0.2416, test_acc : 0.9290\n",
            "----epoch 20----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3525\n",
            "Epoch 20 - train_loss : 0.3525, train_acc : 0.8961, test_loss : 0.2309, test_acc : 0.9310\n",
            "----epoch 21----\n",
            "cluster results of historical [4]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3427\n",
            "Epoch 21 - train_loss : 0.3427, train_acc : 0.8975, test_loss : 0.2226, test_acc : 0.9327\n",
            "----epoch 22----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3330\n",
            "Epoch 22 - train_loss : 0.3330, train_acc : 0.9015, test_loss : 0.2162, test_acc : 0.9337\n",
            "----epoch 23----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3292\n",
            "Epoch 23 - train_loss : 0.3292, train_acc : 0.9026, test_loss : 0.2094, test_acc : 0.9352\n",
            "----epoch 24----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3292\n",
            "Epoch 24 - train_loss : 0.3292, train_acc : 0.9031, test_loss : 0.2082, test_acc : 0.9368\n",
            "----epoch 25----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3157\n",
            "Epoch 25 - train_loss : 0.3157, train_acc : 0.9074, test_loss : 0.2020, test_acc : 0.9375\n",
            "----epoch 26----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3101\n",
            "Epoch 26 - train_loss : 0.3101, train_acc : 0.9091, test_loss : 0.1970, test_acc : 0.9397\n",
            "----epoch 27----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3124\n",
            "Epoch 27 - train_loss : 0.3124, train_acc : 0.9078, test_loss : 0.1877, test_acc : 0.9423\n",
            "----epoch 28----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.3027\n",
            "Epoch 28 - train_loss : 0.3027, train_acc : 0.9109, test_loss : 0.1913, test_acc : 0.9403\n",
            "----epoch 29----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2984\n",
            "Epoch 29 - train_loss : 0.2984, train_acc : 0.9123, test_loss : 0.1847, test_acc : 0.9422\n",
            "----epoch 30----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2946\n",
            "Epoch 30 - train_loss : 0.2946, train_acc : 0.9134, test_loss : 0.1795, test_acc : 0.9450\n",
            "----epoch 31----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2893\n",
            "Epoch 31 - train_loss : 0.2893, train_acc : 0.9147, test_loss : 0.1745, test_acc : 0.9457\n",
            "----epoch 32----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2861\n",
            "Epoch 32 - train_loss : 0.2861, train_acc : 0.9150, test_loss : 0.1728, test_acc : 0.9475\n",
            "----epoch 33----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2805\n",
            "Epoch 33 - train_loss : 0.2805, train_acc : 0.9168, test_loss : 0.1690, test_acc : 0.9488\n",
            "----epoch 34----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2788\n",
            "Epoch 34 - train_loss : 0.2788, train_acc : 0.9189, test_loss : 0.1675, test_acc : 0.9483\n",
            "----epoch 35----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2717\n",
            "Epoch 35 - train_loss : 0.2717, train_acc : 0.9205, test_loss : 0.1617, test_acc : 0.9511\n",
            "----epoch 36----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2680\n",
            "Epoch 36 - train_loss : 0.2680, train_acc : 0.9206, test_loss : 0.1595, test_acc : 0.9523\n",
            "----epoch 37----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2646\n",
            "Epoch 37 - train_loss : 0.2646, train_acc : 0.9207, test_loss : 0.1588, test_acc : 0.9523\n",
            "----epoch 38----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2611\n",
            "Epoch 38 - train_loss : 0.2611, train_acc : 0.9226, test_loss : 0.1528, test_acc : 0.9543\n",
            "----epoch 39----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2637\n",
            "Epoch 39 - train_loss : 0.2637, train_acc : 0.9223, test_loss : 0.1520, test_acc : 0.9542\n",
            "----epoch 40----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2550\n",
            "Epoch 40 - train_loss : 0.2550, train_acc : 0.9239, test_loss : 0.1491, test_acc : 0.9552\n",
            "----epoch 41----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2529\n",
            "Epoch 41 - train_loss : 0.2529, train_acc : 0.9244, test_loss : 0.1463, test_acc : 0.9558\n",
            "----epoch 42----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2537\n",
            "Epoch 42 - train_loss : 0.2537, train_acc : 0.9259, test_loss : 0.1423, test_acc : 0.9574\n",
            "----epoch 43----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2463\n",
            "Epoch 43 - train_loss : 0.2463, train_acc : 0.9273, test_loss : 0.1422, test_acc : 0.9572\n",
            "----epoch 44----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2479\n",
            "Epoch 44 - train_loss : 0.2479, train_acc : 0.9270, test_loss : 0.1430, test_acc : 0.9567\n",
            "----epoch 45----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2463\n",
            "Epoch 45 - train_loss : 0.2463, train_acc : 0.9270, test_loss : 0.1390, test_acc : 0.9576\n",
            "----epoch 46----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2401\n",
            "Epoch 46 - train_loss : 0.2401, train_acc : 0.9288, test_loss : 0.1355, test_acc : 0.9592\n",
            "----epoch 47----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2402\n",
            "Epoch 47 - train_loss : 0.2402, train_acc : 0.9280, test_loss : 0.1355, test_acc : 0.9602\n",
            "----epoch 48----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2356\n",
            "Epoch 48 - train_loss : 0.2356, train_acc : 0.9302, test_loss : 0.1306, test_acc : 0.9607\n",
            "----epoch 49----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2339\n",
            "Epoch 49 - train_loss : 0.2339, train_acc : 0.9318, test_loss : 0.1292, test_acc : 0.9624\n",
            "----epoch 50----\n",
            "cluster results of historical [4 7]\n",
            "cluster results of current [4 7]\n",
            "hey 0.2306\n",
            "Epoch 50 - train_loss : 0.2306, train_acc : 0.9318, test_loss : 0.1306, test_acc : 0.9623\n",
            "---------------------rate 0.275------------------------\n",
            "attackers are  [2, 1]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.7726\n",
            "Epoch 1 - train_loss : 1.7726, train_acc : 0.4510, test_loss : 2.1056, test_acc : 0.3672\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.3597\n",
            "Epoch 2 - train_loss : 1.3597, train_acc : 0.6083, test_loss : 1.4496, test_acc : 0.6144\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.0146\n",
            "Epoch 3 - train_loss : 1.0146, train_acc : 0.7014, test_loss : 0.9460, test_acc : 0.7271\n",
            "----epoch 4----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8 1 2]\n",
            "hey 0.8030\n",
            "Epoch 4 - train_loss : 0.8030, train_acc : 0.7568, test_loss : 0.7102, test_acc : 0.8151\n",
            "----epoch 5----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [1 2]\n",
            "hey 0.6869\n",
            "Epoch 5 - train_loss : 0.6869, train_acc : 0.7899, test_loss : 0.5803, test_acc : 0.8507\n",
            "----epoch 6----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [1 2]\n",
            "hey 0.6103\n",
            "Epoch 6 - train_loss : 0.6103, train_acc : 0.8131, test_loss : 0.4961, test_acc : 0.8723\n",
            "----epoch 7----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [1 2]\n",
            "hey 0.5629\n",
            "Epoch 7 - train_loss : 0.5629, train_acc : 0.8288, test_loss : 0.4339, test_acc : 0.8849\n",
            "----epoch 8----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.5305\n",
            "Epoch 8 - train_loss : 0.5305, train_acc : 0.8398, test_loss : 0.3986, test_acc : 0.8928\n",
            "----epoch 9----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.4941\n",
            "Epoch 9 - train_loss : 0.4941, train_acc : 0.8508, test_loss : 0.3641, test_acc : 0.9003\n",
            "----epoch 10----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.4650\n",
            "Epoch 10 - train_loss : 0.4650, train_acc : 0.8600, test_loss : 0.3371, test_acc : 0.9090\n",
            "----epoch 11----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.4443\n",
            "Epoch 11 - train_loss : 0.4443, train_acc : 0.8681, test_loss : 0.3176, test_acc : 0.9125\n",
            "----epoch 12----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.4247\n",
            "Epoch 12 - train_loss : 0.4247, train_acc : 0.8735, test_loss : 0.2971, test_acc : 0.9188\n",
            "----epoch 13----\n",
            "cluster results of historical [8 1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.4086\n",
            "Epoch 13 - train_loss : 0.4086, train_acc : 0.8790, test_loss : 0.2786, test_acc : 0.9233\n",
            "----epoch 14----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3931\n",
            "Epoch 14 - train_loss : 0.3931, train_acc : 0.8848, test_loss : 0.2637, test_acc : 0.9260\n",
            "----epoch 15----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3816\n",
            "Epoch 15 - train_loss : 0.3816, train_acc : 0.8868, test_loss : 0.2533, test_acc : 0.9291\n",
            "----epoch 16----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3716\n",
            "Epoch 16 - train_loss : 0.3716, train_acc : 0.8891, test_loss : 0.2375, test_acc : 0.9331\n",
            "----epoch 17----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3571\n",
            "Epoch 17 - train_loss : 0.3571, train_acc : 0.8943, test_loss : 0.2325, test_acc : 0.9337\n",
            "----epoch 18----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3519\n",
            "Epoch 18 - train_loss : 0.3519, train_acc : 0.8954, test_loss : 0.2242, test_acc : 0.9348\n",
            "----epoch 19----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3412\n",
            "Epoch 19 - train_loss : 0.3412, train_acc : 0.8995, test_loss : 0.2131, test_acc : 0.9376\n",
            "----epoch 20----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3308\n",
            "Epoch 20 - train_loss : 0.3308, train_acc : 0.9018, test_loss : 0.2063, test_acc : 0.9407\n",
            "----epoch 21----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3228\n",
            "Epoch 21 - train_loss : 0.3228, train_acc : 0.9037, test_loss : 0.1980, test_acc : 0.9427\n",
            "----epoch 22----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3166\n",
            "Epoch 22 - train_loss : 0.3166, train_acc : 0.9071, test_loss : 0.1907, test_acc : 0.9449\n",
            "----epoch 23----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.3061\n",
            "Epoch 23 - train_loss : 0.3061, train_acc : 0.9100, test_loss : 0.1863, test_acc : 0.9457\n",
            "----epoch 24----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2981\n",
            "Epoch 24 - train_loss : 0.2981, train_acc : 0.9135, test_loss : 0.1817, test_acc : 0.9484\n",
            "----epoch 25----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2946\n",
            "Epoch 25 - train_loss : 0.2946, train_acc : 0.9128, test_loss : 0.1757, test_acc : 0.9488\n",
            "----epoch 26----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2887\n",
            "Epoch 26 - train_loss : 0.2887, train_acc : 0.9166, test_loss : 0.1712, test_acc : 0.9495\n",
            "----epoch 27----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2809\n",
            "Epoch 27 - train_loss : 0.2809, train_acc : 0.9170, test_loss : 0.1656, test_acc : 0.9506\n",
            "----epoch 28----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2787\n",
            "Epoch 28 - train_loss : 0.2787, train_acc : 0.9173, test_loss : 0.1601, test_acc : 0.9527\n",
            "----epoch 29----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2735\n",
            "Epoch 29 - train_loss : 0.2735, train_acc : 0.9208, test_loss : 0.1591, test_acc : 0.9517\n",
            "----epoch 30----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2732\n",
            "Epoch 30 - train_loss : 0.2732, train_acc : 0.9208, test_loss : 0.1562, test_acc : 0.9531\n",
            "----epoch 31----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2639\n",
            "Epoch 31 - train_loss : 0.2639, train_acc : 0.9220, test_loss : 0.1516, test_acc : 0.9555\n",
            "----epoch 32----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2643\n",
            "Epoch 32 - train_loss : 0.2643, train_acc : 0.9219, test_loss : 0.1512, test_acc : 0.9550\n",
            "----epoch 33----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2608\n",
            "Epoch 33 - train_loss : 0.2608, train_acc : 0.9234, test_loss : 0.1473, test_acc : 0.9563\n",
            "----epoch 34----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2562\n",
            "Epoch 34 - train_loss : 0.2562, train_acc : 0.9249, test_loss : 0.1428, test_acc : 0.9571\n",
            "----epoch 35----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2489\n",
            "Epoch 35 - train_loss : 0.2489, train_acc : 0.9270, test_loss : 0.1416, test_acc : 0.9579\n",
            "----epoch 36----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2474\n",
            "Epoch 36 - train_loss : 0.2474, train_acc : 0.9277, test_loss : 0.1370, test_acc : 0.9587\n",
            "----epoch 37----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2483\n",
            "Epoch 37 - train_loss : 0.2483, train_acc : 0.9278, test_loss : 0.1383, test_acc : 0.9588\n",
            "----epoch 38----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2443\n",
            "Epoch 38 - train_loss : 0.2443, train_acc : 0.9296, test_loss : 0.1349, test_acc : 0.9598\n",
            "----epoch 39----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2377\n",
            "Epoch 39 - train_loss : 0.2377, train_acc : 0.9311, test_loss : 0.1328, test_acc : 0.9602\n",
            "----epoch 40----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2365\n",
            "Epoch 40 - train_loss : 0.2365, train_acc : 0.9296, test_loss : 0.1296, test_acc : 0.9608\n",
            "----epoch 41----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2360\n",
            "Epoch 41 - train_loss : 0.2360, train_acc : 0.9313, test_loss : 0.1296, test_acc : 0.9601\n",
            "----epoch 42----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2324\n",
            "Epoch 42 - train_loss : 0.2324, train_acc : 0.9327, test_loss : 0.1268, test_acc : 0.9619\n",
            "----epoch 43----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2297\n",
            "Epoch 43 - train_loss : 0.2297, train_acc : 0.9330, test_loss : 0.1242, test_acc : 0.9624\n",
            "----epoch 44----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2275\n",
            "Epoch 44 - train_loss : 0.2275, train_acc : 0.9334, test_loss : 0.1233, test_acc : 0.9620\n",
            "----epoch 45----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2259\n",
            "Epoch 45 - train_loss : 0.2259, train_acc : 0.9344, test_loss : 0.1215, test_acc : 0.9634\n",
            "----epoch 46----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2213\n",
            "Epoch 46 - train_loss : 0.2213, train_acc : 0.9361, test_loss : 0.1206, test_acc : 0.9640\n",
            "----epoch 47----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2211\n",
            "Epoch 47 - train_loss : 0.2211, train_acc : 0.9358, test_loss : 0.1168, test_acc : 0.9648\n",
            "----epoch 48----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2191\n",
            "Epoch 48 - train_loss : 0.2191, train_acc : 0.9355, test_loss : 0.1164, test_acc : 0.9655\n",
            "----epoch 49----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2147\n",
            "Epoch 49 - train_loss : 0.2147, train_acc : 0.9367, test_loss : 0.1152, test_acc : 0.9660\n",
            "----epoch 50----\n",
            "cluster results of historical [1 2]\n",
            "cluster results of current [1 2]\n",
            "hey 0.2163\n",
            "Epoch 50 - train_loss : 0.2163, train_acc : 0.9375, test_loss : 0.1132, test_acc : 0.9661\n",
            "---------------------rate 0.35------------------------\n",
            "attackers are  [8, 7, 2]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.7977\n",
            "Epoch 1 - train_loss : 1.7977, train_acc : 0.4554, test_loss : 2.1462, test_acc : 0.2832\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.3961\n",
            "Epoch 2 - train_loss : 1.3961, train_acc : 0.5981, test_loss : 1.5875, test_acc : 0.4854\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [8 2 7]\n",
            "hey 1.0717\n",
            "Epoch 3 - train_loss : 1.0717, train_acc : 0.6803, test_loss : 1.0996, test_acc : 0.6425\n",
            "----epoch 4----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 1 2 7]\n",
            "hey 0.8686\n",
            "Epoch 4 - train_loss : 0.8686, train_acc : 0.7351, test_loss : 0.8351, test_acc : 0.7428\n",
            "----epoch 5----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.7526\n",
            "Epoch 5 - train_loss : 0.7526, train_acc : 0.7700, test_loss : 0.6864, test_acc : 0.7913\n",
            "----epoch 6----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.6740\n",
            "Epoch 6 - train_loss : 0.6740, train_acc : 0.7927, test_loss : 0.6035, test_acc : 0.8131\n",
            "----epoch 7----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.6133\n",
            "Epoch 7 - train_loss : 0.6133, train_acc : 0.8130, test_loss : 0.5440, test_acc : 0.8340\n",
            "----epoch 8----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.5715\n",
            "Epoch 8 - train_loss : 0.5715, train_acc : 0.8254, test_loss : 0.4879, test_acc : 0.8537\n",
            "----epoch 9----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.5331\n",
            "Epoch 9 - train_loss : 0.5331, train_acc : 0.8379, test_loss : 0.4488, test_acc : 0.8657\n",
            "----epoch 10----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.5082\n",
            "Epoch 10 - train_loss : 0.5082, train_acc : 0.8464, test_loss : 0.4217, test_acc : 0.8737\n",
            "----epoch 11----\n",
            "cluster results of historical [8 1 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.4811\n",
            "Epoch 11 - train_loss : 0.4811, train_acc : 0.8548, test_loss : 0.3817, test_acc : 0.8843\n",
            "----epoch 12----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.4620\n",
            "Epoch 12 - train_loss : 0.4620, train_acc : 0.8604, test_loss : 0.3630, test_acc : 0.8897\n",
            "----epoch 13----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.4382\n",
            "Epoch 13 - train_loss : 0.4382, train_acc : 0.8682, test_loss : 0.3414, test_acc : 0.8967\n",
            "----epoch 14----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.4240\n",
            "Epoch 14 - train_loss : 0.4240, train_acc : 0.8718, test_loss : 0.3245, test_acc : 0.9018\n",
            "----epoch 15----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.4092\n",
            "Epoch 15 - train_loss : 0.4092, train_acc : 0.8776, test_loss : 0.3107, test_acc : 0.9065\n",
            "----epoch 16----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3969\n",
            "Epoch 16 - train_loss : 0.3969, train_acc : 0.8812, test_loss : 0.2928, test_acc : 0.9109\n",
            "----epoch 17----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3865\n",
            "Epoch 17 - train_loss : 0.3865, train_acc : 0.8833, test_loss : 0.2820, test_acc : 0.9148\n",
            "----epoch 18----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3732\n",
            "Epoch 18 - train_loss : 0.3732, train_acc : 0.8902, test_loss : 0.2688, test_acc : 0.9185\n",
            "----epoch 19----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3647\n",
            "Epoch 19 - train_loss : 0.3647, train_acc : 0.8908, test_loss : 0.2623, test_acc : 0.9203\n",
            "----epoch 20----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3541\n",
            "Epoch 20 - train_loss : 0.3541, train_acc : 0.8949, test_loss : 0.2484, test_acc : 0.9260\n",
            "----epoch 21----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3456\n",
            "Epoch 21 - train_loss : 0.3456, train_acc : 0.8971, test_loss : 0.2410, test_acc : 0.9290\n",
            "----epoch 22----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3408\n",
            "Epoch 22 - train_loss : 0.3408, train_acc : 0.8988, test_loss : 0.2297, test_acc : 0.9321\n",
            "----epoch 23----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3298\n",
            "Epoch 23 - train_loss : 0.3298, train_acc : 0.9020, test_loss : 0.2247, test_acc : 0.9340\n",
            "----epoch 24----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3235\n",
            "Epoch 24 - train_loss : 0.3235, train_acc : 0.9044, test_loss : 0.2183, test_acc : 0.9347\n",
            "----epoch 25----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3203\n",
            "Epoch 25 - train_loss : 0.3203, train_acc : 0.9045, test_loss : 0.2131, test_acc : 0.9361\n",
            "----epoch 26----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3105\n",
            "Epoch 26 - train_loss : 0.3105, train_acc : 0.9070, test_loss : 0.2048, test_acc : 0.9391\n",
            "----epoch 27----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.3018\n",
            "Epoch 27 - train_loss : 0.3018, train_acc : 0.9117, test_loss : 0.2035, test_acc : 0.9402\n",
            "----epoch 28----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2940\n",
            "Epoch 28 - train_loss : 0.2940, train_acc : 0.9126, test_loss : 0.1979, test_acc : 0.9413\n",
            "----epoch 29----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2961\n",
            "Epoch 29 - train_loss : 0.2961, train_acc : 0.9134, test_loss : 0.1900, test_acc : 0.9431\n",
            "----epoch 30----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2852\n",
            "Epoch 30 - train_loss : 0.2852, train_acc : 0.9155, test_loss : 0.1840, test_acc : 0.9441\n",
            "----epoch 31----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2839\n",
            "Epoch 31 - train_loss : 0.2839, train_acc : 0.9168, test_loss : 0.1825, test_acc : 0.9454\n",
            "----epoch 32----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2775\n",
            "Epoch 32 - train_loss : 0.2775, train_acc : 0.9184, test_loss : 0.1776, test_acc : 0.9469\n",
            "----epoch 33----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2753\n",
            "Epoch 33 - train_loss : 0.2753, train_acc : 0.9193, test_loss : 0.1767, test_acc : 0.9472\n",
            "----epoch 34----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2695\n",
            "Epoch 34 - train_loss : 0.2695, train_acc : 0.9210, test_loss : 0.1658, test_acc : 0.9500\n",
            "----epoch 35----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2618\n",
            "Epoch 35 - train_loss : 0.2618, train_acc : 0.9229, test_loss : 0.1625, test_acc : 0.9495\n",
            "----epoch 36----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2611\n",
            "Epoch 36 - train_loss : 0.2611, train_acc : 0.9243, test_loss : 0.1596, test_acc : 0.9522\n",
            "----epoch 37----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2550\n",
            "Epoch 37 - train_loss : 0.2550, train_acc : 0.9246, test_loss : 0.1588, test_acc : 0.9528\n",
            "----epoch 38----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2578\n",
            "Epoch 38 - train_loss : 0.2578, train_acc : 0.9250, test_loss : 0.1544, test_acc : 0.9540\n",
            "----epoch 39----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2493\n",
            "Epoch 39 - train_loss : 0.2493, train_acc : 0.9262, test_loss : 0.1550, test_acc : 0.9542\n",
            "----epoch 40----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2485\n",
            "Epoch 40 - train_loss : 0.2485, train_acc : 0.9276, test_loss : 0.1539, test_acc : 0.9532\n",
            "----epoch 41----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2471\n",
            "Epoch 41 - train_loss : 0.2471, train_acc : 0.9273, test_loss : 0.1484, test_acc : 0.9559\n",
            "----epoch 42----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2446\n",
            "Epoch 42 - train_loss : 0.2446, train_acc : 0.9289, test_loss : 0.1467, test_acc : 0.9557\n",
            "----epoch 43----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2368\n",
            "Epoch 43 - train_loss : 0.2368, train_acc : 0.9311, test_loss : 0.1439, test_acc : 0.9569\n",
            "----epoch 44----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2395\n",
            "Epoch 44 - train_loss : 0.2395, train_acc : 0.9302, test_loss : 0.1426, test_acc : 0.9566\n",
            "----epoch 45----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2355\n",
            "Epoch 45 - train_loss : 0.2355, train_acc : 0.9308, test_loss : 0.1438, test_acc : 0.9567\n",
            "----epoch 46----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2381\n",
            "Epoch 46 - train_loss : 0.2381, train_acc : 0.9306, test_loss : 0.1407, test_acc : 0.9571\n",
            "----epoch 47----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2304\n",
            "Epoch 47 - train_loss : 0.2304, train_acc : 0.9332, test_loss : 0.1359, test_acc : 0.9586\n",
            "----epoch 48----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2332\n",
            "Epoch 48 - train_loss : 0.2332, train_acc : 0.9315, test_loss : 0.1393, test_acc : 0.9576\n",
            "----epoch 49----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2253\n",
            "Epoch 49 - train_loss : 0.2253, train_acc : 0.9331, test_loss : 0.1357, test_acc : 0.9584\n",
            "----epoch 50----\n",
            "cluster results of historical [8 2 7]\n",
            "cluster results of current [8 2 7]\n",
            "hey 0.2259\n",
            "Epoch 50 - train_loss : 0.2259, train_acc : 0.9343, test_loss : 0.1286, test_acc : 0.9605\n",
            "---------------------rate 0.425------------------------\n",
            "attackers are  [7, 4, 1, 0]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.7712\n",
            "Epoch 1 - train_loss : 1.7712, train_acc : 0.4610, test_loss : 2.0941, test_acc : 0.3593\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.2986\n",
            "Epoch 2 - train_loss : 1.2986, train_acc : 0.6286, test_loss : 1.4172, test_acc : 0.5807\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [0 1 4]\n",
            "hey 0.9757\n",
            "Epoch 3 - train_loss : 0.9757, train_acc : 0.7110, test_loss : 1.0126, test_acc : 0.6799\n",
            "----epoch 4----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [0 1 4]\n",
            "hey 0.7954\n",
            "Epoch 4 - train_loss : 0.7954, train_acc : 0.7585, test_loss : 0.8077, test_acc : 0.7433\n",
            "----epoch 5----\n",
            "cluster results of historical [9 3 5 6]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.6917\n",
            "Epoch 5 - train_loss : 0.6917, train_acc : 0.7889, test_loss : 0.6636, test_acc : 0.7968\n",
            "----epoch 6----\n",
            "cluster results of historical [9 3 5 6]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.6319\n",
            "Epoch 6 - train_loss : 0.6319, train_acc : 0.8078, test_loss : 0.5758, test_acc : 0.8295\n",
            "----epoch 7----\n",
            "cluster results of historical [9 3 5 6]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.5725\n",
            "Epoch 7 - train_loss : 0.5725, train_acc : 0.8265, test_loss : 0.5200, test_acc : 0.8471\n",
            "----epoch 8----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.5347\n",
            "Epoch 8 - train_loss : 0.5347, train_acc : 0.8378, test_loss : 0.4759, test_acc : 0.8589\n",
            "----epoch 9----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.5036\n",
            "Epoch 9 - train_loss : 0.5036, train_acc : 0.8473, test_loss : 0.4392, test_acc : 0.8693\n",
            "----epoch 10----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.4804\n",
            "Epoch 10 - train_loss : 0.4804, train_acc : 0.8555, test_loss : 0.4015, test_acc : 0.8812\n",
            "----epoch 11----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.4522\n",
            "Epoch 11 - train_loss : 0.4522, train_acc : 0.8627, test_loss : 0.3913, test_acc : 0.8823\n",
            "----epoch 12----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.4351\n",
            "Epoch 12 - train_loss : 0.4351, train_acc : 0.8694, test_loss : 0.3605, test_acc : 0.8940\n",
            "----epoch 13----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.4175\n",
            "Epoch 13 - train_loss : 0.4175, train_acc : 0.8747, test_loss : 0.3464, test_acc : 0.8948\n",
            "----epoch 14----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3949\n",
            "Epoch 14 - train_loss : 0.3949, train_acc : 0.8812, test_loss : 0.3214, test_acc : 0.9039\n",
            "----epoch 15----\n",
            "cluster results of historical [0 1 4]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3876\n",
            "Epoch 15 - train_loss : 0.3876, train_acc : 0.8843, test_loss : 0.3100, test_acc : 0.9047\n",
            "----epoch 16----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3761\n",
            "Epoch 16 - train_loss : 0.3761, train_acc : 0.8875, test_loss : 0.3108, test_acc : 0.9036\n",
            "----epoch 17----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3631\n",
            "Epoch 17 - train_loss : 0.3631, train_acc : 0.8921, test_loss : 0.2926, test_acc : 0.9079\n",
            "----epoch 18----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3556\n",
            "Epoch 18 - train_loss : 0.3556, train_acc : 0.8939, test_loss : 0.2797, test_acc : 0.9153\n",
            "----epoch 19----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3443\n",
            "Epoch 19 - train_loss : 0.3443, train_acc : 0.8991, test_loss : 0.2736, test_acc : 0.9139\n",
            "----epoch 20----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3410\n",
            "Epoch 20 - train_loss : 0.3410, train_acc : 0.8996, test_loss : 0.2675, test_acc : 0.9143\n",
            "----epoch 21----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3258\n",
            "Epoch 21 - train_loss : 0.3258, train_acc : 0.9033, test_loss : 0.2564, test_acc : 0.9202\n",
            "----epoch 22----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3173\n",
            "Epoch 22 - train_loss : 0.3173, train_acc : 0.9052, test_loss : 0.2494, test_acc : 0.9230\n",
            "----epoch 23----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3175\n",
            "Epoch 23 - train_loss : 0.3175, train_acc : 0.9055, test_loss : 0.2469, test_acc : 0.9214\n",
            "----epoch 24----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3067\n",
            "Epoch 24 - train_loss : 0.3067, train_acc : 0.9089, test_loss : 0.2356, test_acc : 0.9271\n",
            "----epoch 25----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.3035\n",
            "Epoch 25 - train_loss : 0.3035, train_acc : 0.9110, test_loss : 0.2383, test_acc : 0.9242\n",
            "----epoch 26----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2980\n",
            "Epoch 26 - train_loss : 0.2980, train_acc : 0.9112, test_loss : 0.2357, test_acc : 0.9240\n",
            "----epoch 27----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2920\n",
            "Epoch 27 - train_loss : 0.2920, train_acc : 0.9146, test_loss : 0.2299, test_acc : 0.9258\n",
            "----epoch 28----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2820\n",
            "Epoch 28 - train_loss : 0.2820, train_acc : 0.9165, test_loss : 0.2119, test_acc : 0.9360\n",
            "----epoch 29----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2770\n",
            "Epoch 29 - train_loss : 0.2770, train_acc : 0.9179, test_loss : 0.2160, test_acc : 0.9314\n",
            "----epoch 30----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2739\n",
            "Epoch 30 - train_loss : 0.2739, train_acc : 0.9187, test_loss : 0.2236, test_acc : 0.9220\n",
            "----epoch 31----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2726\n",
            "Epoch 31 - train_loss : 0.2726, train_acc : 0.9188, test_loss : 0.2024, test_acc : 0.9386\n",
            "----epoch 32----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2715\n",
            "Epoch 32 - train_loss : 0.2715, train_acc : 0.9193, test_loss : 0.2088, test_acc : 0.9347\n",
            "----epoch 33----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2646\n",
            "Epoch 33 - train_loss : 0.2646, train_acc : 0.9216, test_loss : 0.2054, test_acc : 0.9335\n",
            "----epoch 34----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2610\n",
            "Epoch 34 - train_loss : 0.2610, train_acc : 0.9228, test_loss : 0.2030, test_acc : 0.9337\n",
            "----epoch 35----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2552\n",
            "Epoch 35 - train_loss : 0.2552, train_acc : 0.9245, test_loss : 0.1930, test_acc : 0.9392\n",
            "----epoch 36----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2549\n",
            "Epoch 36 - train_loss : 0.2549, train_acc : 0.9251, test_loss : 0.1920, test_acc : 0.9405\n",
            "----epoch 37----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2531\n",
            "Epoch 37 - train_loss : 0.2531, train_acc : 0.9246, test_loss : 0.1988, test_acc : 0.9342\n",
            "----epoch 38----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2468\n",
            "Epoch 38 - train_loss : 0.2468, train_acc : 0.9280, test_loss : 0.1927, test_acc : 0.9384\n",
            "----epoch 39----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2422\n",
            "Epoch 39 - train_loss : 0.2422, train_acc : 0.9275, test_loss : 0.1897, test_acc : 0.9384\n",
            "----epoch 40----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2453\n",
            "Epoch 40 - train_loss : 0.2453, train_acc : 0.9274, test_loss : 0.1814, test_acc : 0.9432\n",
            "----epoch 41----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2427\n",
            "Epoch 41 - train_loss : 0.2427, train_acc : 0.9288, test_loss : 0.1810, test_acc : 0.9444\n",
            "----epoch 42----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2381\n",
            "Epoch 42 - train_loss : 0.2381, train_acc : 0.9297, test_loss : 0.1827, test_acc : 0.9431\n",
            "----epoch 43----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2351\n",
            "Epoch 43 - train_loss : 0.2351, train_acc : 0.9303, test_loss : 0.1861, test_acc : 0.9407\n",
            "----epoch 44----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2309\n",
            "Epoch 44 - train_loss : 0.2309, train_acc : 0.9322, test_loss : 0.1783, test_acc : 0.9453\n",
            "----epoch 45----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2265\n",
            "Epoch 45 - train_loss : 0.2265, train_acc : 0.9332, test_loss : 0.1726, test_acc : 0.9476\n",
            "----epoch 46----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2290\n",
            "Epoch 46 - train_loss : 0.2290, train_acc : 0.9327, test_loss : 0.1772, test_acc : 0.9444\n",
            "----epoch 47----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2270\n",
            "Epoch 47 - train_loss : 0.2270, train_acc : 0.9332, test_loss : 0.1743, test_acc : 0.9462\n",
            "----epoch 48----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2242\n",
            "Epoch 48 - train_loss : 0.2242, train_acc : 0.9323, test_loss : 0.1782, test_acc : 0.9444\n",
            "----epoch 49----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2236\n",
            "Epoch 49 - train_loss : 0.2236, train_acc : 0.9343, test_loss : 0.1689, test_acc : 0.9489\n",
            "----epoch 50----\n",
            "cluster results of historical [0 1 4 7]\n",
            "cluster results of current [0 1 4 7]\n",
            "hey 0.2211\n",
            "Epoch 50 - train_loss : 0.2211, train_acc : 0.9338, test_loss : 0.1739, test_acc : 0.9462\n",
            "---------------------rate 0.475------------------------\n",
            "attackers are  [0, 8, 6, 1]\n",
            "----epoch 1----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.7747\n",
            "Epoch 1 - train_loss : 1.7747, train_acc : 0.4691, test_loss : 2.0887, test_acc : 0.3735\n",
            "----epoch 2----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 5 6]\n",
            "hey 1.3261\n",
            "Epoch 2 - train_loss : 1.3261, train_acc : 0.6174, test_loss : 1.4580, test_acc : 0.5224\n",
            "----epoch 3----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [9 2 4 5]\n",
            "hey 0.9980\n",
            "Epoch 3 - train_loss : 0.9980, train_acc : 0.7016, test_loss : 1.0024, test_acc : 0.6901\n",
            "----epoch 4----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [2 3 4 5 9]\n",
            "hey 0.7933\n",
            "Epoch 4 - train_loss : 0.7933, train_acc : 0.7588, test_loss : 0.7648, test_acc : 0.7822\n",
            "----epoch 5----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.6806\n",
            "Epoch 5 - train_loss : 0.6806, train_acc : 0.7917, test_loss : 0.6385, test_acc : 0.8167\n",
            "----epoch 6----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.6064\n",
            "Epoch 6 - train_loss : 0.6064, train_acc : 0.8154, test_loss : 0.5426, test_acc : 0.8497\n",
            "----epoch 7----\n",
            "cluster results of historical [9 5 6]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.5439\n",
            "Epoch 7 - train_loss : 0.5439, train_acc : 0.8351, test_loss : 0.4649, test_acc : 0.8753\n",
            "----epoch 8----\n",
            "cluster results of historical [9 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.5043\n",
            "Epoch 8 - train_loss : 0.5043, train_acc : 0.8477, test_loss : 0.4102, test_acc : 0.8919\n",
            "----epoch 9----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.4716\n",
            "Epoch 9 - train_loss : 0.4716, train_acc : 0.8583, test_loss : 0.3816, test_acc : 0.8973\n",
            "----epoch 10----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.4414\n",
            "Epoch 10 - train_loss : 0.4414, train_acc : 0.8678, test_loss : 0.3561, test_acc : 0.9026\n",
            "----epoch 11----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.4256\n",
            "Epoch 11 - train_loss : 0.4256, train_acc : 0.8722, test_loss : 0.3362, test_acc : 0.9068\n",
            "----epoch 12----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.4092\n",
            "Epoch 12 - train_loss : 0.4092, train_acc : 0.8770, test_loss : 0.3171, test_acc : 0.9116\n",
            "----epoch 13----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3917\n",
            "Epoch 13 - train_loss : 0.3917, train_acc : 0.8826, test_loss : 0.3009, test_acc : 0.9160\n",
            "----epoch 14----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3766\n",
            "Epoch 14 - train_loss : 0.3766, train_acc : 0.8883, test_loss : 0.2893, test_acc : 0.9193\n",
            "----epoch 15----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3630\n",
            "Epoch 15 - train_loss : 0.3630, train_acc : 0.8927, test_loss : 0.2784, test_acc : 0.9212\n",
            "----epoch 16----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3536\n",
            "Epoch 16 - train_loss : 0.3536, train_acc : 0.8944, test_loss : 0.2689, test_acc : 0.9235\n",
            "----epoch 17----\n",
            "cluster results of historical [9 2 4 5]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3505\n",
            "Epoch 17 - train_loss : 0.3505, train_acc : 0.8951, test_loss : 0.2573, test_acc : 0.9268\n",
            "----epoch 18----\n",
            "cluster results of historical [0 1 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3343\n",
            "Epoch 18 - train_loss : 0.3343, train_acc : 0.9015, test_loss : 0.2437, test_acc : 0.9291\n",
            "----epoch 19----\n",
            "cluster results of historical [0 1 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3307\n",
            "Epoch 19 - train_loss : 0.3307, train_acc : 0.9019, test_loss : 0.2386, test_acc : 0.9323\n",
            "----epoch 20----\n",
            "cluster results of historical [0 1 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3149\n",
            "Epoch 20 - train_loss : 0.3149, train_acc : 0.9061, test_loss : 0.2330, test_acc : 0.9337\n",
            "----epoch 21----\n",
            "cluster results of historical [0 1 6 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3121\n",
            "Epoch 21 - train_loss : 0.3121, train_acc : 0.9066, test_loss : 0.2308, test_acc : 0.9339\n",
            "----epoch 22----\n",
            "cluster results of historical [0 1 6 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3033\n",
            "Epoch 22 - train_loss : 0.3033, train_acc : 0.9106, test_loss : 0.2171, test_acc : 0.9386\n",
            "----epoch 23----\n",
            "cluster results of historical [0 1 6 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.3006\n",
            "Epoch 23 - train_loss : 0.3006, train_acc : 0.9099, test_loss : 0.2158, test_acc : 0.9378\n",
            "----epoch 24----\n",
            "cluster results of historical [0 1 6 8]\n",
            "cluster results of current [0 1 6 8]\n",
            "hey 0.2943\n",
            "Epoch 24 - train_loss : 0.2943, train_acc : 0.9124, test_loss : 0.2098, test_acc : 0.9407\n",
            "----epoch 25----\n"
          ]
        }
      ]
    }
  ]
}